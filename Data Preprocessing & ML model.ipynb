{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:05:53.888815900Z",
     "start_time": "2023-08-31T01:05:53.825818200Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:05:54.070816300Z",
     "start_time": "2023-08-31T01:05:53.842816600Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('OnlineNewsPopularity.csv')\n",
    "data.columns = [col.strip() for col in data.columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create isolation forest model to remove outliers\n",
    "[API Link to IF](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html#sklearn.ensemble.IsolationForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:05:54.491814900Z",
     "start_time": "2023-08-31T01:05:54.072816400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total 3965 rows been removied.\n"
     ]
    }
   ],
   "source": [
    "old_data_length = len(data)\n",
    "IF_model = IsolationForest(contamination=0.1) # Remove 10% data\n",
    "outliers = IF_model.fit_predict(data.drop(columns=['url', 'timedelta', 'shares'])) # Delete columns than don't need in IF and train IF model\n",
    "data['outliers'] = outliers\n",
    "\n",
    "# Remove outliers\n",
    "data_outliers = data[data['outliers'] == -1]\n",
    "new_data = data[data['outliers'] != -1].drop(columns = ['outliers'])\n",
    "\n",
    "new_data_len = len(new_data)\n",
    "\n",
    "print(f\"There are total {old_data_length - new_data_len} rows been removied.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creat a function to classify an article to different categories\n",
    "* Great Article: Shares >= 90%\n",
    "* Good Article: 70% <= Shares < 90%\n",
    "* Normal Article: 30% <= Shares < 70%\n",
    "* Bad article: Shares < 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:05:54.528815600Z",
     "start_time": "2023-08-31T01:05:54.487816400Z"
    }
   },
   "outputs": [],
   "source": [
    "def article_classifier(shares, top_percent):\n",
    "    if shares >= top_percent[0.9]:\n",
    "        return 'Great'\n",
    "    elif shares >= top_percent[0.7]:\n",
    "        return 'Good'\n",
    "    elif shares >= top_percent[0.3]:\n",
    "        return 'Normal'\n",
    "    else:\n",
    "        return 'Bad'\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:05:56.068535900Z",
     "start_time": "2023-08-31T01:05:54.501816500Z"
    }
   },
   "outputs": [],
   "source": [
    "top_percent = new_data['shares'].quantile([0.3, 0.7, 0.9])\n",
    "\n",
    "quality = []\n",
    "for index, row in new_data.iterrows():\n",
    "    quality.append(article_classifier(row['shares'], top_percent))\n",
    "\n",
    "new_data['quality'] = quality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into x and y and one-hot encode quality column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:05:56.097536300Z",
     "start_time": "2023-08-31T01:05:56.072535300Z"
    }
   },
   "outputs": [],
   "source": [
    "x = new_data.drop(columns=['quality', 'url', 'timedelta', 'shares'], axis=1)\n",
    "y = OneHotEncoder().fit_transform(new_data[['quality']]).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:05:56.128535900Z",
     "start_time": "2023-08-31T01:05:56.098537Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.2, random_state=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the data to Improve the speed of training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:05:56.161544400Z",
     "start_time": "2023-08-31T01:05:56.130535900Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scale_xTrain = scaler.fit_transform(xTrain)\n",
    "scale_xTest = scaler.fit_transform(xTest)\n",
    "\n",
    "#standard_scaler = StandardScaler()\n",
    "#scale_xTrain = standard_scaler.fit_transform(xTrain)\n",
    "#scale_xTest = standard_scaler.transform(xTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create and train model(NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:06:24.759097300Z",
     "start_time": "2023-08-31T01:05:56.162545500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 20:25:46.496558: W tensorflow/core/framework/dataset.cc:956] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892/892 [==============================] - 1s 1ms/step - loss: 1.2249 - accuracy: 0.4277\n",
      "Epoch 2/10\n",
      "892/892 [==============================] - 1s 816us/step - loss: 1.2055 - accuracy: 0.4373\n",
      "Epoch 3/10\n",
      "892/892 [==============================] - 1s 804us/step - loss: 1.1972 - accuracy: 0.4422\n",
      "Epoch 4/10\n",
      "892/892 [==============================] - 1s 802us/step - loss: 1.1915 - accuracy: 0.4448\n",
      "Epoch 5/10\n",
      "892/892 [==============================] - 1s 802us/step - loss: 1.1856 - accuracy: 0.4486\n",
      "Epoch 6/10\n",
      "892/892 [==============================] - 1s 797us/step - loss: 1.1818 - accuracy: 0.4528\n",
      "Epoch 7/10\n",
      "892/892 [==============================] - 1s 804us/step - loss: 1.1767 - accuracy: 0.4534\n",
      "Epoch 8/10\n",
      "892/892 [==============================] - 1s 835us/step - loss: 1.1730 - accuracy: 0.4530\n",
      "Epoch 9/10\n",
      "892/892 [==============================] - 1s 858us/step - loss: 1.1693 - accuracy: 0.4563\n",
      "Epoch 10/10\n",
      "892/892 [==============================] - 1s 921us/step - loss: 1.1652 - accuracy: 0.4593\n",
      "Epoch 1/10\n",
      "892/892 [==============================] - 1s 800us/step - loss: 1.2278 - accuracy: 0.4268\n",
      "Epoch 2/10\n",
      "892/892 [==============================] - 1s 800us/step - loss: 1.2057 - accuracy: 0.4396\n",
      "Epoch 3/10\n",
      "892/892 [==============================] - 1s 809us/step - loss: 1.1968 - accuracy: 0.4424\n",
      "Epoch 4/10\n",
      "892/892 [==============================] - 1s 843us/step - loss: 1.1907 - accuracy: 0.4461\n",
      "Epoch 5/10\n",
      "892/892 [==============================] - 1s 807us/step - loss: 1.1841 - accuracy: 0.4516\n",
      "Epoch 6/10\n",
      "892/892 [==============================] - 1s 802us/step - loss: 1.1798 - accuracy: 0.4507\n",
      "Epoch 7/10\n",
      "892/892 [==============================] - 1s 803us/step - loss: 1.1752 - accuracy: 0.4543\n",
      "Epoch 8/10\n",
      "892/892 [==============================] - 1s 863us/step - loss: 1.1712 - accuracy: 0.4561\n",
      "Epoch 9/10\n",
      "892/892 [==============================] - 1s 842us/step - loss: 1.1679 - accuracy: 0.4573\n",
      "Epoch 10/10\n",
      "892/892 [==============================] - 1s 815us/step - loss: 1.1644 - accuracy: 0.4589\n"
     ]
    }
   ],
   "source": [
    "def build_nn_model(input_shape, num_classes):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "mirror_strategy = tf.distribute.MirroredStrategy()\n",
    "with mirror_strategy.scope():\n",
    "    nn_model1 = build_nn_model(scale_xTrain.shape[1:], yTrain.shape[1])\n",
    "    nn_model2 = build_nn_model(scale_xTrain.shape[1:], yTrain.shape[1])\n",
    "\n",
    "    fit_speed = tf.data.Dataset.from_tensor_slices((scale_xTrain, yTrain))\n",
    "    fit_speed = fit_speed.repeat().batch(100)\n",
    "\n",
    "    nn_model1.fit(scale_xTrain, yTrain, epochs=10)\n",
    "    nn_model2.fit(scale_xTrain, yTrain, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train model(Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:06:41.546106200Z",
     "start_time": "2023-08-31T01:06:24.757451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_model = RandomForestClassifier(n_estimators=100)\n",
    "RF_model.fit(scale_xTrain, yTrain.argmax(axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions with each model individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892/892 [==============================] - 0s 478us/step\n",
      "892/892 [==============================] - 0s 465us/step\n",
      "223/223 [==============================] - 0s 567us/step\n",
      "223/223 [==============================] - 0s 575us/step\n",
      "Shape:\n",
      "nn1_train_pred: (28543, 4)\n",
      "nn2_train_pred: (28543, 4)\n",
      "RF_train_pred: (28543, 4)\n",
      "Labels:\n",
      "nn1_train_pred: [0 0 3 ... 0 3 0]\n",
      "nn2_train_pred: [0 0 3 ... 0 3 0]\n",
      "RF_train_pred: [0 3 0 ... 1 3 3]\n",
      "nn1_test_pred: [3 3 0 ... 3 3 3]\n",
      "nn2_test_pred: [3 3 0 ... 3 3 3]\n",
      "RF_test_pred: [3 3 0 ... 3 3 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn1_train_pred = nn_model1.predict(scale_xTrain)\n",
    "nn2_train_pred = nn_model2.predict(scale_xTrain)\n",
    "RF_train_pred = RF_model.predict_proba(scale_xTrain)\n",
    "\n",
    "nn1_test_pred = nn_model1.predict(scale_xTest)\n",
    "nn2_test_pred = nn_model2.predict(scale_xTest)\n",
    "RF_test_pred = RF_model.predict_proba(scale_xTest)\n",
    "\n",
    "print(\"Shape:\")\n",
    "print(\"nn1_train_pred:\", nn1_train_pred.shape)\n",
    "print(\"nn2_train_pred:\", nn2_train_pred.shape)\n",
    "print(\"RF_train_pred:\", RF_train_pred.shape)\n",
    "\n",
    "nn1_train_labels = nn1_train_pred.argmax(axis=1)\n",
    "nn2_train_labels = nn2_train_pred.argmax(axis=1)\n",
    "RF_train_labels = RF_train_pred.argmax(axis=1)\n",
    "\n",
    "nn1_test_labels = nn1_test_pred.argmax(axis=1)\n",
    "nn2_test_labels = nn2_test_pred.argmax(axis=1)\n",
    "RF_test_labels = RF_test_pred.argmax(axis=1)\n",
    "\n",
    "print(\"Labels:\")\n",
    "print(\"nn1_train_pred:\", nn1_train_labels)\n",
    "print(\"nn2_train_pred:\", nn2_train_labels)\n",
    "print(\"RF_train_pred:\", RF_train_labels)\n",
    "print(\"nn1_test_pred:\", nn1_test_labels)\n",
    "print(\"nn2_test_pred:\", nn2_test_labels)\n",
    "print(\"RF_test_pred:\", RF_test_labels)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Ensemble: 3 linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the 3 linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linmodel_1 = LinearRegression()\n",
    "linmodel_2 = LinearRegression()\n",
    "linmodel_3 = LinearRegression()\n",
    "\n",
    "linmodel_1.fit(scale_xTrain,yTrain)\n",
    "linmodel_2.fit(scale_xTrain,yTrain)\n",
    "linmodel_3.fit(scale_xTrain,yTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the predictions out of the 3 linear regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "linmodel1_train_pred = linmodel_1.predict(scale_xTrain)\n",
    "linmodel2_train_pred = linmodel_2.predict(scale_xTrain)\n",
    "linmodel3_train_pred = linmodel_3.predict(scale_xTrain)\n",
    "\n",
    "linmodel1_test_pred = linmodel_1.predict(scale_xTest)\n",
    "linmodel2_test_pred = linmodel_2.predict(scale_xTest)\n",
    "linmodel3_test_pred = linmodel_3.predict(scale_xTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the ensemble prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_simple_train_pred = (linmodel1_train_pred + linmodel2_train_pred + linmodel3_train_pred) / 3\n",
    "ensemble_simple_test_pred = (linmodel1_test_pred + linmodel2_test_pred + linmodel3_test_pred) / 3\n",
    "\n",
    "ensemble_simple_train_labels = ensemble_simple_train_pred.argmax(axis=1)\n",
    "ensemble_simple_test_labels = ensemble_simple_test_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Simple Ensemble) Classification Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.49      0.48      8382\n",
      "           1       0.38      0.05      0.08      5713\n",
      "           2       0.34      0.03      0.05      2873\n",
      "           3       0.44      0.72      0.55     11575\n",
      "\n",
      "    accuracy                           0.45     28543\n",
      "   macro avg       0.41      0.32      0.29     28543\n",
      "weighted avg       0.43      0.45      0.38     28543\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.88      0.42      2067\n",
      "           1       0.00      0.00      0.00      1433\n",
      "           2       0.00      0.00      0.00       702\n",
      "           3       0.39      0.08      0.13      2934\n",
      "\n",
      "    accuracy                           0.29      7136\n",
      "   macro avg       0.17      0.24      0.14      7136\n",
      "weighted avg       0.24      0.29      0.17      7136\n",
      "\n",
      "Training error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junminkim/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/junminkim/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/junminkim/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\")\n",
    "print(classification_report(yTrain.argmax(axis=1), ensemble_simple_train_labels))\n",
    "print(\"Test:\")\n",
    "print(classification_report(yTest.argmax(axis=1), ensemble_simple_test_labels))\n",
    "\n",
    "print(\"Training error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Complex Ensemble: 2 NN + 1 RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble_train_labels: [0 3 0 ... 0 3 3]\n",
      "ensemble_train_labels: [0 3 0 ... 0 3 3]\n"
     ]
    }
   ],
   "source": [
    "ensemble_train_pred = (nn1_train_pred + nn2_train_pred + RF_train_pred) / 3\n",
    "ensemble_test_pred = (nn1_test_pred + nn2_test_pred + RF_test_pred) / 3\n",
    "\n",
    "ensemble_train_labels = ensemble_train_pred.argmax(axis=1)\n",
    "ensemble_test_labels = ensemble_test_pred.argmax(axis=1)\n",
    "\n",
    "print(\"ensemble_train_labels:\",ensemble_train_labels)\n",
    "print(\"ensemble_train_labels:\",ensemble_train_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91      8382\n",
      "           1       0.98      0.78      0.87      5713\n",
      "           2       1.00      0.60      0.75      2873\n",
      "           3       0.85      0.99      0.91     11575\n",
      "\n",
      "    accuracy                           0.89     28543\n",
      "   macro avg       0.93      0.82      0.86     28543\n",
      "weighted avg       0.90      0.89      0.89     28543\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.23      0.32      2067\n",
      "           1       0.41      0.21      0.27      1433\n",
      "           2       0.20      0.06      0.10       702\n",
      "           3       0.43      0.79      0.56      2934\n",
      "\n",
      "    accuracy                           0.44      7136\n",
      "   macro avg       0.40      0.32      0.31      7136\n",
      "weighted avg       0.44      0.44      0.39      7136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\")\n",
    "print(classification_report(yTrain.argmax(axis=1), ensemble_train_labels))\n",
    "print(\"Test:\")\n",
    "print(classification_report(yTest.argmax(axis=1), ensemble_test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Train Accuracies:\n",
      "Neural Network 1: 0.4654\n",
      "Neural Network 2: 0.4654\n",
      "Random Forest: 1.0000\n",
      "\n",
      "Model Test Accuracies:\n",
      "Neural Network 1: 0.4375\n",
      "Neural Network 2: 0.4268\n",
      "Random Forest: 0.4165\n",
      "\n",
      "Ensemble Model:\n",
      "Training Accuracy: 0.8902\n",
      "Testing Accuracy: 0.4395\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "nn1_train_accuracy = accuracy_score(yTrain.argmax(axis=1), nn1_train_labels)\n",
    "nn2_train_accuracy = accuracy_score(yTrain.argmax(axis=1), nn2_train_labels)\n",
    "RF_train_accuracy = accuracy_score(yTrain.argmax(axis=1), RF_train_labels)\n",
    "\n",
    "nn1_test_accuracy = accuracy_score(yTest.argmax(axis=1), nn1_test_labels)\n",
    "nn2_test_accuracy = accuracy_score(yTest.argmax(axis=1), nn2_test_labels)\n",
    "RF_test_accuracy = accuracy_score(yTest.argmax(axis=1), RF_test_labels)\n",
    "\n",
    "ensemble_train_accuracy = accuracy_score(yTrain.argmax(axis=1), ensemble_train_labels)\n",
    "ensemble_test_accuracy = accuracy_score(yTest.argmax(axis=1), ensemble_test_labels)\n",
    "\n",
    "print(\"Model Train Accuracies:\")\n",
    "print(f\"Neural Network 1: {nn1_train_accuracy:.4f}\")\n",
    "print(f\"Neural Network 2: {nn2_train_accuracy:.4f}\")\n",
    "print(f\"Random Forest: {RF_train_accuracy:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Model Test Accuracies:\")\n",
    "print(f\"Neural Network 1: {nn1_test_accuracy:.4f}\")\n",
    "print(f\"Neural Network 2: {nn2_test_accuracy:.4f}\")\n",
    "print(f\"Random Forest: {RF_test_accuracy:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Ensemble Model:\")\n",
    "print(f\"Training Accuracy: {ensemble_train_accuracy:.4f}\")\n",
    "print(f\"Testing Accuracy: {ensemble_test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
