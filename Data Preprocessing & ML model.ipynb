{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:05:53.888815900Z",
     "start_time": "2023-08-31T01:05:53.825818200Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:05:54.070816300Z",
     "start_time": "2023-08-31T01:05:53.842816600Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('OnlineNewsPopularity.csv')\n",
    "data.columns = [col.strip() for col in data.columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create isolation forest model to remove outliers\n",
    "[API Link to IF](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html#sklearn.ensemble.IsolationForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:05:54.491814900Z",
     "start_time": "2023-08-31T01:05:54.072816400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total 3965 rows been removied.\n"
     ]
    }
   ],
   "source": [
    "old_data_length = len(data)\n",
    "IF_model = IsolationForest(contamination=0.1) # Remove 10% data\n",
    "outliers = IF_model.fit_predict(data.drop(columns=['url', 'timedelta', 'shares'])) # Delete columns than don't need in IF and train IF model\n",
    "data['outliers'] = outliers\n",
    "\n",
    "# Remove outliers\n",
    "data_outliers = data[data['outliers'] == -1]\n",
    "new_data = data[data['outliers'] != -1].drop(columns = ['outliers'])\n",
    "\n",
    "new_data_len = len(new_data)\n",
    "\n",
    "print(f\"There are total {old_data_length - new_data_len} rows been removied.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creat a function to classify an article to different categories\n",
    "* Great Article: Shares >= 90%\n",
    "* Good Article: 70% <= Shares < 90%\n",
    "* Normal Article: 30% <= Shares < 70%\n",
    "* Bad article: Shares < 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:05:54.528815600Z",
     "start_time": "2023-08-31T01:05:54.487816400Z"
    }
   },
   "outputs": [],
   "source": [
    "def article_classifier(shares, top_percent):\n",
    "    if shares >= top_percent[0.9]:\n",
    "        return 'Great'\n",
    "    elif shares >= top_percent[0.7]:\n",
    "        return 'Good'\n",
    "    elif shares >= top_percent[0.3]:\n",
    "        return 'Normal'\n",
    "    else:\n",
    "        return 'Bad'\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:05:56.068535900Z",
     "start_time": "2023-08-31T01:05:54.501816500Z"
    }
   },
   "outputs": [],
   "source": [
    "top_percent = new_data['shares'].quantile([0.3, 0.7, 0.9])\n",
    "\n",
    "quality = []\n",
    "for index, row in new_data.iterrows():\n",
    "    quality.append(article_classifier(row['shares'], top_percent))\n",
    "\n",
    "new_data['quality'] = quality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into x and y and one-hot encode quality column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:05:56.097536300Z",
     "start_time": "2023-08-31T01:05:56.072535300Z"
    }
   },
   "outputs": [],
   "source": [
    "x = new_data.drop(columns=['quality', 'url', 'timedelta', 'shares'], axis=1)\n",
    "y = OneHotEncoder().fit_transform(new_data[['quality']]).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:05:56.128535900Z",
     "start_time": "2023-08-31T01:05:56.098537Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.2, random_state=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the data to Improve the speed of training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:05:56.161544400Z",
     "start_time": "2023-08-31T01:05:56.130535900Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standard_scaler = StandardScaler()\n",
    "scale_xTrain = standard_scaler.fit_transform(xTrain)\n",
    "scale_xTest = standard_scaler.transform(xTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create and train model(NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:06:24.759097300Z",
     "start_time": "2023-08-31T01:05:56.162545500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Epoch 1/10\n",
      "892/892 [==============================] - 2s 1ms/step - loss: 1.2175 - accuracy: 0.4304\n",
      "Epoch 2/10\n",
      "892/892 [==============================] - 1s 1ms/step - loss: 1.1830 - accuracy: 0.4494\n",
      "Epoch 3/10\n",
      "892/892 [==============================] - 1s 1ms/step - loss: 1.1686 - accuracy: 0.4600\n",
      "Epoch 4/10\n",
      "892/892 [==============================] - 1s 1ms/step - loss: 1.1586 - accuracy: 0.4661\n",
      "Epoch 5/10\n",
      "892/892 [==============================] - 1s 1ms/step - loss: 1.1481 - accuracy: 0.4712\n",
      "Epoch 6/10\n",
      "892/892 [==============================] - 1s 1ms/step - loss: 1.1379 - accuracy: 0.4793\n",
      "Epoch 7/10\n",
      "892/892 [==============================] - 1s 1ms/step - loss: 1.1263 - accuracy: 0.4868\n",
      "Epoch 8/10\n",
      "892/892 [==============================] - 1s 1ms/step - loss: 1.1137 - accuracy: 0.4910\n",
      "Epoch 9/10\n",
      "892/892 [==============================] - 1s 1ms/step - loss: 1.1031 - accuracy: 0.4978\n",
      "Epoch 10/10\n",
      "892/892 [==============================] - 1s 1ms/step - loss: 1.0893 - accuracy: 0.5092\n",
      "Epoch 1/10\n",
      "892/892 [==============================] - 2s 1ms/step - loss: 1.2201 - accuracy: 0.4223\n",
      "Epoch 2/10\n",
      "892/892 [==============================] - 1s 1ms/step - loss: 1.1830 - accuracy: 0.4452\n",
      "Epoch 3/10\n",
      "892/892 [==============================] - 1s 1ms/step - loss: 1.1695 - accuracy: 0.4550\n",
      "Epoch 4/10\n",
      "892/892 [==============================] - 1s 1ms/step - loss: 1.1598 - accuracy: 0.4610\n",
      "Epoch 5/10\n",
      "892/892 [==============================] - 1s 1ms/step - loss: 1.1484 - accuracy: 0.4685\n",
      "Epoch 6/10\n",
      "892/892 [==============================] - 1s 1ms/step - loss: 1.1370 - accuracy: 0.4748\n",
      "Epoch 7/10\n",
      "892/892 [==============================] - 1s 1ms/step - loss: 1.1247 - accuracy: 0.4845\n",
      "Epoch 8/10\n",
      "892/892 [==============================] - 1s 1ms/step - loss: 1.1119 - accuracy: 0.4919\n",
      "Epoch 9/10\n",
      "892/892 [==============================] - 1s 1ms/step - loss: 1.0987 - accuracy: 0.5023\n",
      "Epoch 10/10\n",
      "892/892 [==============================] - 1s 1ms/step - loss: 1.0840 - accuracy: 0.5100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def build_nn_model(input_shape, num_classes):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "mirror_strategy = tf.distribute.MirroredStrategy()\n",
    "with mirror_strategy.scope():\n",
    "    nn_model1 = build_nn_model(scale_xTrain.shape[1:], yTrain.shape[1])\n",
    "    nn_model2 = build_nn_model(scale_xTrain.shape[1:], yTrain.shape[1])\n",
    "\n",
    "    fit_speed = tf.data.Dataset.from_tensor_slices((scale_xTrain, yTrain))\n",
    "    fit_speed = fit_speed.repeat().batch(100)\n",
    "\n",
    "    nn_model1.fit(scale_xTrain, yTrain, epochs=10)\n",
    "    nn_model2.fit(scale_xTrain, yTrain, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train model(Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:06:41.546106200Z",
     "start_time": "2023-08-31T01:06:24.757451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_model = RandomForestClassifier(n_estimators=100)\n",
    "RF_model.fit(scale_xTrain, yTrain.argmax(axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions with each model individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892/892 [==============================] - 1s 1ms/step\n",
      "892/892 [==============================] - 1s 906us/step\n",
      "223/223 [==============================] - 0s 1ms/step\n",
      "223/223 [==============================] - 0s 1ms/step\n",
      "Shape\n",
      "nn1_train_pred: (28543, 4)\n",
      "nn2_train_pred: (28543, 4)\n",
      "RF_train_pred: (28543, 4)\n",
      "\n",
      "Labels\n",
      "nn1_train_pred: [3 3 2 ... 3 3 1]\n",
      "nn2_train_pred: [0 3 2 ... 0 1 3]\n",
      "RF_train_pred: [3 3 1 ... 3 2 1]\n",
      "nn1_test_pred: [1 3 0 ... 1 2 0]\n",
      "nn2_test_pred: [3 1 0 ... 0 1 0]\n",
      "RF_test_pred: [3 3 0 ... 3 3 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn1_train_pred = nn_model1.predict(scale_xTrain)\n",
    "nn2_train_pred = nn_model2.predict(scale_xTrain)\n",
    "RF_train_pred = RF_model.predict_proba(scale_xTrain)\n",
    "\n",
    "nn1_test_pred = nn_model1.predict(scale_xTest)\n",
    "nn2_test_pred = nn_model2.predict(scale_xTest)\n",
    "RF_test_pred = RF_model.predict_proba(scale_xTest)\n",
    "\n",
    "print(\"Shape:\")\n",
    "print(\"nn1_train_pred:\", nn1_train_pred.shape)\n",
    "print(\"nn2_train_pred:\", nn2_train_pred.shape)\n",
    "print(\"RF_train_pred:\", RF_train_pred.shape)\n",
    "\n",
    "nn1_train_labels = nn1_train_pred.argmax(axis=1)\n",
    "nn2_train_labels = nn2_train_pred.argmax(axis=1)\n",
    "RF_train_labels = RF_train_pred.argmax(axis=1)\n",
    "\n",
    "nn1_test_labels = nn1_test_pred.argmax(axis=1)\n",
    "nn2_test_labels = nn2_test_pred.argmax(axis=1)\n",
    "RF_test_labels = RF_test_pred.argmax(axis=1)\n",
    "\n",
    "print(\"Labels:\")\n",
    "print(\"nn1_train_pred:\", nn1_train_labels)\n",
    "print(\"nn2_train_pred:\", nn2_train_labels)\n",
    "print(\"RF_train_pred:\", RF_train_labels)\n",
    "print(\"nn1_test_pred:\", nn1_test_labels)\n",
    "print(\"nn2_test_pred:\", nn2_test_labels)\n",
    "print(\"RF_test_pred:\", RF_test_labels)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble_train_labels: [3 3 1 ... 3 1 1]\n",
      "ensemble_train_labels: [3 3 1 ... 3 1 1]\n"
     ]
    }
   ],
   "source": [
    "ensemble_train_pred = (nn1_train_pred + nn2_train_pred + RF_train_pred) / 3\n",
    "ensemble_test_pred = (nn1_test_pred + nn2_test_pred + RF_test_pred) / 3\n",
    "\n",
    "ensemble_train_labels = ensemble_train_pred.argmax(axis=1)\n",
    "ensemble_test_labels = ensemble_test_pred.argmax(axis=1)\n",
    "\n",
    "print(\"ensemble_train_labels:\",ensemble_train_labels)\n",
    "print(\"ensemble_train_labels:\",ensemble_train_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88      8446\n",
      "           1       0.94      0.78      0.85      6110\n",
      "           2       0.99      0.59      0.74      2843\n",
      "           3       0.83      0.95      0.88     11144\n",
      "\n",
      "    accuracy                           0.87     28543\n",
      "   macro avg       0.90      0.81      0.84     28543\n",
      "weighted avg       0.88      0.87      0.86     28543\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.51      0.51      2031\n",
      "           1       0.46      0.18      0.26      1551\n",
      "           2       0.35      0.07      0.12       742\n",
      "           3       0.43      0.66      0.52      2812\n",
      "\n",
      "    accuracy                           0.45      7136\n",
      "   macro avg       0.44      0.36      0.35      7136\n",
      "weighted avg       0.45      0.45      0.42      7136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\")\n",
    "print(classification_report(yTrain.argmax(axis=1), ensemble_train_labels))\n",
    "print(\"Test:\")\n",
    "print(classification_report(yTest.argmax(axis=1), ensemble_test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Train Accuracies:\n",
      "Neural Network 1: 0.5331\n",
      "Neural Network 2: 0.5285\n",
      "Random Forest: 1.0000\n",
      "\n",
      "Model Test Accuracies:\n",
      "Neural Network 1: 0.4393\n",
      "Neural Network 2: 0.4326\n",
      "Random Forest: 0.4420\n",
      "\n",
      "Ensemble Model:\n",
      "Training Accuracy: 0.8657\n",
      "Testing Accuracy: 0.4545\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "nn1_train_accuracy = accuracy_score(yTrain.argmax(axis=1), nn1_train_labels)\n",
    "nn2_train_accuracy = accuracy_score(yTrain.argmax(axis=1), nn2_train_labels)\n",
    "RF_train_accuracy = accuracy_score(yTrain.argmax(axis=1), RF_train_labels)\n",
    "\n",
    "nn1_test_accuracy = accuracy_score(yTest.argmax(axis=1), nn1_test_labels)\n",
    "nn2_test_accuracy = accuracy_score(yTest.argmax(axis=1), nn2_test_labels)\n",
    "RF_test_accuracy = accuracy_score(yTest.argmax(axis=1), RF_test_labels)\n",
    "\n",
    "ensemble_train_accuracy = accuracy_score(yTrain.argmax(axis=1), ensemble_train_labels)\n",
    "ensemble_test_accuracy = accuracy_score(yTest.argmax(axis=1), ensemble_test_labels)\n",
    "\n",
    "print(\"Model Train Accuracies:\")\n",
    "print(f\"Neural Network 1: {nn1_train_accuracy:.4f}\")\n",
    "print(f\"Neural Network 2: {nn2_train_accuracy:.4f}\")\n",
    "print(f\"Random Forest: {RF_train_accuracy:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Model Test Accuracies:\")\n",
    "print(f\"Neural Network 1: {nn1_test_accuracy:.4f}\")\n",
    "print(f\"Neural Network 2: {nn2_test_accuracy:.4f}\")\n",
    "print(f\"Random Forest: {RF_test_accuracy:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Ensemble Model:\")\n",
    "print(f\"Training Accuracy: {ensemble_train_accuracy:.4f}\")\n",
    "print(f\"Testing Accuracy: {ensemble_test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
